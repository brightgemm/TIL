# ADsP 자격증





## 1. 데이터의 이해

   

### 01. 데이터의 이해

#### 데이터의 특성

- 존재적 특성: 객관적 사실
- 당위적 특성: 추론, 예측, 전망, 추정을 위한 근거

#### 데이터의 유형

- 정성적: 비정형
- 정량적: 정형
  - 수치로 명확하게 표현되는 데이터. 양이 커도 DBMS에 저장, 검색, 분석하기 쉬움

#### 지식경영의 핵심이슈

- 암묵지: 개인의 내면화된 지식 -> 조직 지식으로 공통화
- 형식지: 언어, 기호, 숫자로 표출화된 지식 -> 개인 지식으로 연결화
- 암묵지와 형식지의 상호작용: 공통화 -> 표출화 -> 연결화 -> 내면화
  - 표출화:개인의 내재된 경험을 객관적인 데이터로 문서나 매체에 저장, 가공, 분석하는 과정

#### DIKW

- 데이터 > 정보 > 지식 > 지혜

   

#### 데이터베이스

- 정형데이터 관리 -> 빅데이터 출현으로 비정형데이터 관리까지 포함

#### 데이터베이스 구성요소

- 메타데이터: 데이터에 관한 구조화된 데이터. 다른 데이터를 설명해 주는 데이터
- 인덱스: 데이터베이스의 테이블에서 고속 검색, 레코드 접근과 관련한 효율적인 순서 매김 동작에 대한 기초 제공

#### 데이터베이스 특징

- intergrated: 중복없는 통합 데이터
- sorted: 저장 매체에 저장
- shared: 복수의 이용자가 서로 다른 목적으로. 복잡
- changeable: 데이터 삽입, 삭제, 갱신 등. 현재의 정확한 데이터 유지해야 함
- 기계가독성, 검색가독성, 원격조작성
- 신속한 정보획득, 경제적으로 검색 가능
- 체계적인 축적, 내용 추가 및 갱신 용이
- 정보기술 발전에 영향
- 경제, 산업 발전에 영향

#### 기업 내부 데이터베이스

- OLTP(On-Line Transaction Processing): 호스트 컴퓨터가 DB 엑세스 및 관리. 데이터 갱신 위주
- OLAP(On-Line Analytical Processing): 정보 위주의 분석 처리.  데이터 조회 위주
- CRM(Customer Relationship Management): 고객관계관리
- SCM(Supply Chain Management): 공급망 관리
  - 기업이 외부 공급업체 또는 제휴업체와 통합된 정보시스템으로 연계하여 시간과 비용을 최적화시키기 위한 것
  - 자재 구매, 생산, 제고, 유통, 판매, 고객 데이터로 구성
- 제조분야
  - ERP(Enterprise Resource Planning): 전사적 자원 관리. 인사, 재무, 생산 등 통합 시스템으로 관리
  - CRM: 고객 중심 자원 극대화
  - BI(Business Intelligence): 기업 보유 데이터를 분석하여 의사결정에 활용하는 프로세스
  - RTE(Real Time Enterprise): 회사 전 부분의 정보를 하나로 통합. 실시간 기업 경영시스템
- 금융부문
  - EAI(Enterprise Application Integration): 상호 연관된 앱을 연동하여 중앙집중적 정보 관리
  - EDW(Enterprise Data Warehouse): DW를 전사적으로 확장. BPR(업무 재설계), CRM, BSC(균형성과표) 등 분석 앱의 원천
- 유통부문
  - KMS(Knowledge Management System): 지식관리시스템
  - RFID(Radio Frequency ID): 주파수를 이용해 ID 식별. 전자태그
- EDI(Electric Data Interchange): 표준화된 양식을 통해 전자적 신호로 바꿔 컴퓨터로 거래처에 전송하는 시스템
- VAN(Value Added Network): 부가가치통신망. 독자적인 네트워크로 정보 교환, 축적, 전송 등
- CALS(Commerce At Light Speed): 전자상거래 구축을 위한 경영통합정보시스템. 컴퓨터를 활용한 자동화시스템
- 물류부문
  - CVO(Commercial Vehicle Operation System): 화물운송정보
  - PORT-MIS: 항만운영정보시스템
  - KROIS: 철도운영정보시스템
- 지리/교통부문
  - GIS: 지리정보시스템
  - RS: 원격탐사
  - GPS
  - ITS: 지능형교통시스템
  - LBS: 위치기반서비스
  - SIM: 공간정보관리
- 의료부문
  - PACS(Picture Archiving and Communication System)
  - U-health
- 교육부문
  - NEIS

#### 데이터웨어하우스(DW)

- 기업 내의 의사결정지원 어플리케이션에 정보 기반을 제공하는 하나의 통합된 데이터 저장 공간
- 기업의 의사결정 과정을 지원하기 위한 주제 중심적으로 통합적이며 시간성을 가지는 비휘발성 데이터의 집합
- 특성
  - 데이터의 주제 지향성
  - 데이터 통합
  - 데이터의 시계열성
  - 데이터의 비휘발성

   

   

### 02. 데이터의 가치와 미래

#### 빅데이터의 정의

> 관점에 따라 3가지로 정의

- 좁은 범위의 정의: 3V (Volume, Variety, Velocity) + (Value, Visualization, Veracity) 
- 중간 범위의 정의: + 기술 변화(데이터 처리, 저장, 분석 기술 및 아키텍쳐, 클라우드 컴퓨팅) 포함
- 넒은 범위의 정의: + 인재, 조직 변화(데이터사이언티스트 등장)

#### 빅데이터 출현 배경

- 고객데이터의 축적
- 거대 데이터 활용 증가
- 기술 아키텍처 및 통계 도구 발전
- 모바일 혁명

#### 빅데이터 비유

- 산업혁명의 석탄, 철
- 21세기의 원유
- 렌즈
- 플랫폼

#### 빅데이터로 인한 변화

- 사전처리 -> 사후처리
- 표본조사 -> 전수조사
- 질 -> 양
- 인과관계 -> 상관관계

#### 빅데이터 활용

- 연관규칙학습
- 유형분석
- 유전자 알고리즘
- 기계학습
- 회귀분석
- 감정분석
- 소셜네트워크분석(사회관계망분석)



##### [기출] 비즈니스 모델

- 플랫폼형 비즈니스 모델: 서비스, 기술 등의 기반 위에 다른 이해관계자들이 보완적인 상품, 서비스, 기술을 제공하는 생태계 구축을 목표로 하는 모델
- 가치사슬형 비즈니스 모델: 가치사슬상의 중요 분야를 수직계열화해서 기업의 효율성 증진 Ex) 자라
- 사회적 가치 기반형 비즈니스 모델
- 고객 중심형 비즈니스 모델



#### 빅데이터 시대의 위기 요인 및 통제 방안

- 사생활 침해 -> 동의에서 책임으로
- 책임 원칙 훼손 -> 결과 기반 책임 원칙 고수
- 데이터 오용 -> 알고리즘 접근 허용

   

   

### 03. 가치창조를 위한 데이터사이언스와 전략 인사이트

#### 데이터 사이언스

- 데이터로부터 의미있는 정보를 추출해내는 학문. 다양한 유형의 데이터를 대상으로 분석 및 효과적인 구현과 전달 과정까지 포함
- 데이터 사이언스의 구성요소
  - Analytics: 수학, 확률모델 머신러닝, 분석학 등
  - 비즈니스 분석: 비즈니스 컨설팅 영역. 커뮤니케이션, 프레젠테이션, 스토리텔링, 시각화 등
  - IT: 데이터 처리와 관련된 IT 영역. 시그널 프로세싱, 프로그래밍, 데이터 엔지니어링, DW 등

#### 데이터 사이언티스트의 역할 및 역량

- 데이터 홍수 속에서 소스를 찾고 대용량 데이터를 구조화, 연결해야 함
- 강력한 호기심 필요. 문제의 이면을 파고들어 질문과 가설을 세우는 능력
- 스토리텔링, 커뮤니케이션, 창의력, 열정, 직관력, 비판적 시각, 글쓰기 능력, 대화능력 등 필요

- Hard Skill
  - 빅데이터에 대한 이론적 지식
  - 분석 기술에 대한 숙련
- Soft Skill
  - 통찰력 있는 분석
  - 설득력 있는 전달
  - 다분야간 협력

#### 인문학 열풍의 이유

- 컨버전스 -> 디버전스: 단순세계화에서 복잡한 세계화로의 변화
- 생산 -> 서비스: 비즈니스 중심이 제품생산에서 서비스로 이동
- 생산 -> 시장창조: 공급자 중심의 기술경쟁에서 무형자산의 경쟁으로 변화

   

### 04. 빅데이터 상식

#### DBMS

- Data Base Management System

- 데이터베이스를 관리하여 응용 프로그램들이 DB를 공유하며 사용할 수 있는 환경을 제공하는 소프트웨어
- DB 구축 틀 제공, 효율적인 데이터 검색, 저장 기능 제공
- Ex. 오라클, 인포믹스, 액세스 등

#### DBMS 종류

- 관계형 DBMS
  - 데이터를 컬럼과 로우를 이루는 하나 이상의 테이블로 정리. 프라이머리키가 각 로우 식별
  - 로우는 레코드 또는 튜플로 부르며, 일반적으로 각 테이블/관계는 하나의 entity type을 대표함
  - 로우는 그 entity 종류의 인스턴스를 대표, 컬럼은 인스턴스의 속성을 대표
- 객체지향 DBMS
  - 정보를 객체 형태로 표현하는 DB 모델
  - 사용자 정의 데이터 및 멀티미디어 데이터 등 복잡한 데이터 구조를 표현, 관리
- 네트워크 DBMS
  - 레코드와 레코드 사이의 관계를 노드와 간선으로 표현하는 그래프를 기반으로 하는 DB 모델
- 계층형 DBMS
  - 트리 구조를 기반으로 하는 계층 DB 모델

   

#### SQL

- Structured Query Language
- DB에 접근할 수 있는 DB 하부 언어

#### SQL 집계함수

- AVG: 평균
- COUNT: 개수 (**수치형, 문자형 모두 가능**)
- SUM: 합계
- STDDEV: 분산
- MIN: 최솟값
- MAX: 최댓값

   

#### 개인정보 비식별 기술

- 데이터 마스킹: 홍길동 -> 홍**
- 가명처리: 홍길동 -> 임꺽정
- 총계처리: 데이터의 총합만 노출. 개별 데이터 노출X
- 데이터값 삭제: 홍길동 35세 서울거주 한국대 졸업 -> 35세 서울거주
- 데이터 범주화: 홍길동 35세 -> 홍씨 30대

   

#### 데이터 무결성

- Data Integrity. 데이터의 일관성, 유효성, 신뢰성을 보장하기 위해 데이터 변경 시 제한 두기
- 개체 무결성
- 참조 무결성
- 범위 무결성

   

#### 데이터 레이크

- Data Lake
- 대용량의 정형 및 비정형 데이터 저장소
- 별도로 정제되지 않은 자연스러운 상태의 아주 큰 데이터 세트

   

#### 블록체인

- 거래정보를 하나의 덩어리로 보고 이를 차례로 연결한 거래장부
- 거래에 참여하는 모든 사용자에게 거래내역을 보내 주며 거래 때마다 이를 대조하여 데이터 위조 방지

   

#### 빅데이터 분석기술

- 하둡: 여러 개의 컴퓨터를 하나인 것처럼 묶어 대용량 데이터 처리하는 기술. 분산파일시스템
- Apache Spark: 실시간 분산형 컴퓨팅 플랫폼. in-memory 방식으로 처리 속도가 빠름
- Smart Factory: 공장 내 설비와 기계에 IoT 설치. 실시간 공정 데이터
- 머신러닝, 딥러닝: 인공지능, 인공신경망

   

#### 데이터 단위

- 바이트 < 킬로바이트 < 메가 < 기가 < 테라 < 페타 < 엑사 < 제타 < 요타

#### 데이터 유형

- 정형: 형태(고정된 필드) 있음, 연산 가능, 주로 RDBMS에 저장
- 반정형: 형태(스키마, 메타데이터) 있음, 연산 불가, **주로 파일로 저장**
- 비정형: 형태 없음, 주로 NoSQL에 저장

   

   

   

## 2. 데이터 분석 기획

### 01. 데이터 분석 기획의 이해

#### 분석기획의 특징

- 분석기획: 분석 수행 전 과제 정의, 관리 방안 등 사전에 계획하는 일련의 작업
- What, Why, How에 대한 계획 수립
- 데이터 사이언티스트는 수학/통계학적 지식 + 정보기술 + 도메인 지식 필요

#### 분석 대상과 방법

<table>
  <tr>
    <td colspan=2>분석 대상(What)</td>
  </tr>
  <tr>
    <td>known</td>
    <td>unknown</td>
  </tr>
  <tr>
    <td>Optimization</td>
    <td>Insight</td>
    <td>known</td>
    <td rowspan=2>분석 방법(How)</td>
  </tr>
  <tr>
    <td>Solution</td>
    <td>Discovery</td>
    <td>unknown</td>
  </tr>
</table>

#### 목표시점별 분석 기획 방안

- 과제 중심적 접근 방식: 당면한 과제를 빠르게 해결. 단기적
- 장기적인 마스터 플랜 방식: 지속적인 분석과제 정의. 중장기적
- 의미있는 분석 = 분석 기술 + IT 및 프로그래밍 + 도메인 전문성 + 의사소통

<table>
  <tr>
    <td></td>
    <td>과제 중심적 접근 방식</td>
    <td>마스터 플랜 방식</td>
  </tr>
  <tr>
    <td>1차 목표</td>
    <td>speed/test</td>
    <td>accuracy/deploy</td>
  </tr>
  <tr>
    <td>과제 유형</td>
    <td>quick/win</td>
    <td>long term view</td>
  </tr>
  <tr>
    <td>접근 방식</td>
    <td>문제 해결</td>
    <td>문제 정의</td>
  </tr>
</table>

#### 분석 기획 시 고려사항

- 가용 데이터(Available Data): 데이터 확보 우선. 데이터 유형에 따라 방법이 다르므로 유형 분석이 선행되어야 함
  - transaction data, human-generated data, mobile data, machine and sensor data
- 적절한 활용방안과 유즈케이스(Proper Business Use Case): 기존의 유사 분석 시나리오 및 솔루션 활용
  - 고객 분석, 소셜미디어 분석, 플랜트 및 시설 관리, 파이프라인 관리, 가격최적화, 사기 탐지
- 장애 요소들에 대한 사전 계획 수립(Low Berrier of Execution): 지속적인 변화 관리 필요
  - cost, simplicity, performance. culture

   

#### 분석 방법론

- 방법론의 구성: 절차, 방법, 도구와 기업, 템플릿과 산출물
- 데이터 기반 의사결정의 장애요소
  - 경험과 감에 따른 의사결정
  - 고정관념, 편향된 생각, 프레이밍 효과(문제의 표현 방식에 따라 동일한 내용임에도 개인의 선택이 달라질 수 있는 현상)
- 방법론 생성과정
  - 암묵지 -> 형식화 -> 형식지 -> 체계화 -> 방법론 -> 내재화 -> 암묵지
- 방법론 적용 업무의 특성에 따른 모델
  - 폭포수 모델: 단계를 순차적으로 진행
  - 프로토타입 모델: 점진적으로 시스템 개발하는 방식. 고객의 요구 분석이 어려울 때 일부분을 우선 개발 -> 성능 평가 -> 개선 작업
  - 나선형 모델: 반복을 통해 점증적으로 개발하는 방법. 처음 시도하는 프로젝트에 적용 쉬움. 복잡도 상승으로 프로젝트 진행이 어려울 수 있음
- 방법론의 구성(빅데이터 분석의 계층적 프로세스)
  - 단계(단계별 완료 보고서) > 태스크(보고서) > 스탭(보고서 구성요소)
  - 단계: 최상위 계층. 완성된 단계별 산출물 생성. 각 단계는 버전관리 등으로 통제
  - 태스크: 단계를 구성하는 단위 활동. 물리적, 논리적 단위로 품질검토 항목이 됨
  - 스텝: WBS의 워크 패키지에 해당. 입력자료, 처리 및 도구, 출력자료로 구성된 단위 프로세스

#### KDD 분석 방법론

- KDD(Knowledge Discovery in Database): 프로파일링 기술을 기반으로 데이터로부터 통계적 패턴 등을 찾기 위해 체계적으로 정리한 데이터 마이닝 프로세스
- 분석 절차
  - 데이터셋 선택(Selection): 비즈니스 도메인에 대한 이해와 프로젝트 목표 설정, 목표데이터 구성
  - 데이터 전처리(Preprocessing): 잡음, 이상치, 결측치 식별 및 처리. 추가로 요구되는 데이터가 있을 시 selection 재실행
  - 데이터 변환(Transformation): 분석 목적에 맞게 변수 생성, 데이터 차원 축소. 학습용/검증용 데이터 분리
  - 데이터 마이닝(Data Mining): 분석 목적에 맞는 데이터마이닝 기법 선택하여 알고리즘 실행. 필요에 따라 전처리/변환 재실행
  - 데이터 마이닝 결과 평가(Interpretation/Evaluation): 결과에 대한 해석과 평가, 목적과의 일치성 확인

#### CRISP-DM 분석 방법론

- Cross Industry Standard PRocess for Data Mining: 계층적 프로세스 모델. 4가지 레벨과 6단계로 이루어짐
- 4레벨 구조
  - Phases > Generic Tasks > Specialized Tasks >Process Instances
  - 최상위 레벨은 여러 단계(Phases)로 구성. 각 단계는 일반화 태스크(Generic Tasks)를 포함
  - 일반화 테스크는 데이터마이닝의 단일 프로세스를 완전하게 수행하는 단위. 세분화 태스크(Specialized Tasks)로 구성
    - Ex. 데이터 정제(=일반화 태스크)는 범주형 데이터 정제와 연속형 데이터 정제(=세분화 태스크)로 구성됨
  - 프로세스 실행(Process Instances)는 데이터마이닝을 위한 구체적인 실행 포함
- 프로세스 6단계
  - 업무 이해(Business Understanding): 비즈니스 관점에서 목적과 요구사항 이해. 데이터 분석을 위한 문제정의
  - 데이터 이해(Data Understanding): 데이터 수집, 속성 분석, 인사이트 발견
  - 데이터 준비(Data Preparation): 수집된 데이터에서 분석기법에 적합한 데이터 선택(시간 소요)
  - 모델링(Modeling): 모델링 기법과 알고리즘 선택, 파라미터 최적화, 모델 평가
  - 평가(Evaluation): 분석결과 평가, 모델링 과정 평가, 모델 적용성 평가
  - 전개(Deployment): 실 업무에 적용 계획 수립, 유지보수 계획 수립, 프로젝트 종료 보고서 및 리뷰

#### KDD VS CRISP-DM

<table>
  <tr>
    <td>KDD</td>
    <td>CRISP-DM</td>
  </tr>
  <tr>
    <td>분석대상 비즈니스 이해</td>
    <td>업무 이해</td>
  </tr>
  <tr>
    <td>데이터셋 선택</td>
    <td rowspan=2>데이터의 이해</td>
  </tr>
  <tr>
    <td>데이터 전처리</td>
  </tr>
  <tr>
    <td>데이터 변환</td>
    <td>데이터 준비</td>
  </tr>
  <tr>
    <td>데이터마이닝</td>
    <td>모델링</td>
  </tr>
  <tr>
    <td>데이터마이닝 결과 평가</td>
    <td>평가</td>
  </tr>
  <tr>
    <td>데이터마이닝 활용</td>
    <td>전개</td>
  </tr>
</table>

   

#### 빅데이터 분석 방법론

- 빅데이터 분석 계층적 프로세스
  - 단계(Phase) > 태스크(Task) > 스탭(step)
- 분석 방법론 5단계
  - 분석기획 -> 데이터 준비 -> 데이터 분석 -> 시스템 구현 -> 평가 및 전개
  - 분석기획
    - 비즈니스 이해 및 범위설정 -> 비즈니스 이해 및 도메인 문제점, 프로젝트 범위 정의서(SOW)
    - 프로젝트 정의 및 계획수립 -> 프로젝트 정의서, 모델 운영 이미지 설계서, 모델 평가 기준, 프로젝트 수행계획서, WBS
    - 프로젝트 위험계획 수립 -> 식별된 위험목록, 위험관리 계획서
  - 데이터 준비
    - 필요 데이터 정의 -> 데이터 정의서, 데이터 획득 계획서
    - 데이터 스토어 설계 -> 정형 데이터 스토어 설계서, 비정형 데이터 스토어 설계서, 데이터 매핑 정의서
    - 데이터 수집 및 정합성 점검 -> 수집된 분석용 데이터, 정합성 점검 보고서
  - 데이터 분석
    - 분석용 데이터 준비 -> 비즈니스 룰, 분석에 필요한 데이터 범위, 분석용 데이터셋
    - 텍스트 분석 -> 분석용 텍스트 데이터, 텍스트 분석 보고서
    - 탐색적 분석 -> 데이터 탐색 보고서, 데이터 시각화 보고서
    - 모델링 -> 훈련용/테스트용 데이터, 모델링 결과 보고서, 알고리점 설명서, 모니터링 방안
    - 모델 평가 및 검증 -> 모델 평가 보고서, 모델 검증 보고서
  - 시스템 구현
    - 설계 및 구현 -> 시스템 분석 및 설계서, 구현 시스템
    - 시스템 테스트 및 운영 -> 시스템 테스트 결과보고서, 운영자 매뉴얼, 사용자 매뉴얼, 시스템 운영계획서
  - 평가 및 전개
    - 모델 발전 계획 수립 -> 모델 발전 계획서
    - 프로젝트 평가 및 보고 -> 프로젝트 성과 평가서, 프로젝트 최종 보고서

   

#### 분석과제 발굴 방법론

- 하향식 접근 방법: 현황 분석을 통해 문제 탐색 -> 문제 정의 -> 해결방안 탐색 -> 타당성 평가 -> 분석과제 도출. Why 관점
  - 비즈니스 모델 기반 문제 탐색
    - [업무, 제품, 고객], 규제와 감사, 지원 인프라
  - 분석 기회 발굴의 범위 확장 - 4가지 관점
    - 거시적 관점: 사회, 기술, 경제, 환경, 정치
    - 경쟁자 확대: 대체재, 경쟁자, 신규 진입자
    - 시장니즈 탐색: 고객, 채널, 영향자들
    - 역량의 재해석: 내부역량, 파트너 네트워크
  - 타당검 검토 대상: 경제성, 데이터, 기술
- 상향식 접근 방법: 기업에서 보유하고 있는 다양한 원천 데이터로부터 분석을 통하여 통찰력과 지식을 얻는 접근 방식. What 관점
  - 일번적으로 비지도 학습 방법의 의해 수행
  - 프로토타이핑 접근법: 일단 분석을 시도해 보고 결과를 확인해 가면서 반복적으로 개선해 나가는 방법
    - 신속한 해결책이나 모형 제시 -> 문제 인식 및 데이터를 구체화할 수 있기 하는 상향식 접근 방식
    - 가설 생성 -> 디자인에 대한 실험 -> 실제 환경에서 테스트 -> 인사이트 도출 및 가설 확인
    - 프로토타이핑의 필요성: 문제에 대한 낮은 인식 수준, 필요 데이터의 존재 여부 불확실성, 데이터 사용 목적이 가변성

- 디자인 사고: 상향식 접근 방식과 하향식 접근 방식을 반복적으로 수행하는 상호 보완적인 동적 환경을 통해 분석의 가치를 높일 수 있는 최적의 의사결정 방식

   

#### 분석과제 관리를 위한 5가지 주요 영역

- 데이터 크기(Data Size): 분석하고자 하는 데이터의 양
- 데이터 복잡성(Data Complexity): 데이터에 잘 적용될 수 있는 분석 모델의 선정
- 속도(Speed): 분석 모델의 성능 및 속도를 고려한 개발
- 분석 복잡도(Analytic Complexity): 해석이 가능하면서도 정확도를 올릴 수 있는 최적 모델 탐색
- 정확도&일관성(Accuracy&Precision): 모델과 실제 값 사이의 정확도(활용성), 지속적으로 반복했을 때의 일관성(안전성)

#### 분석 프로젝트의 관리 방안

- 범위
- 시간
- 원가
- 품질
- 통합
- 조달
- 자원
- 리스트
- 의사소통
- 이해관계자

   

   

### 02. 분석 마스터 플랜

#### 분석 마스터 플랜 수립 프레임 워크

- 마스터 플랜 수립 시 고려해야 할 요소
  - 우선순위 고려요소: 적용 우선 순위 설정
    - 전략적 중요도, 비즈니스 성과/ROI, 실행 용이성
  - 적용범위/방식 고려요소: 분석 구현 로드맵 수립
    - 업무 내재화 적용 수준, 분석 데이터 적용 수준, 기술 적용 수준
- ISP(Information Strategy Planning): 정보기술 또는 정보시스템을 전략적으로 활용하기 위하여 조직 내외부 환경을 분석하여 기회나 문제점을 도출하고 사용자의 요구사항을 분석하여 시스템 구축 우선순위를 결정하는 등 중장기 마스터 플랜을 수립하는 절차
- 분석 마스터 플랜: 일반적인 ISP 방법론을 활용하되 데이터 분석 기획의 특성을 고려하여 수행하고 분석과제를 빠짐없이 도출한 후 과제의 우선순위 결정하고 단기 및 중장기로 나누어 계획 수립